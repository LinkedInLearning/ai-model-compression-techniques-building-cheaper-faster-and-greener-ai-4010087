{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO1kPG7ckohCKRESNivQKHT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Pip Install"],"metadata":{"id":"zxcYH7ld2jTM"}},{"cell_type":"code","source":["!pip install torch torchvision numpy matplotlib"],"metadata":{"id":"iVbWdMaX2kRo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747685239893,"user_tz":420,"elapsed":87770,"user":{"displayName":"Tejas Chopra","userId":"08409025920690368673"}},"outputId":"c274470f-cebc-4390-b40b-60eae957d703"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"]}]},{"cell_type":"markdown","source":["Imports and Initialization"],"metadata":{"id":"eRkdkRQ22tzY"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","import time\n","import copy\n","import os\n","import gc\n","import torch.utils.mobile_optimizer as mobile_optimizer\n","from torch.nn.utils import prune\n","\n","\n","# Set random seeds for reproducibility\n","torch.manual_seed(42)\n","np.random.seed(42)\n","\n","\n","# Check if CUDA is available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n"],"metadata":{"id":"rLE-z5F620Ou","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747700659708,"user_tz":420,"elapsed":8911,"user":{"displayName":"Tejas Chopra","userId":"08409025920690368673"}},"outputId":"90cc2aa7-58a9-47af-acf0-0b335c4c1e75"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda:0\n"]}]},{"cell_type":"markdown","source":["Model Definition"],"metadata":{"id":"uz8odwcu20uP"}},{"cell_type":"code","source":["# Define a simple CNN model\n","class SimpleCNN(nn.Module):\n","   def __init__(self, in_channels=1, conv1_channels=32, conv2_channels=64, fc1_units=128, fc2_units=10):\n","       super(SimpleCNN, self).__init__()\n","       self.conv1 = nn.Conv2d(in_channels, conv1_channels, kernel_size=3, padding=1)\n","       self.conv2 = nn.Conv2d(conv1_channels, conv2_channels, kernel_size=3, padding=1)\n","       self.pool = nn.MaxPool2d(2, 2)\n","       self.fc1 = nn.Linear(conv2_channels * 7 * 7, fc1_units)\n","       self.fc2 = nn.Linear(fc1_units, fc2_units)\n","       self.relu = nn.ReLU()\n","\n","\n","   def forward(self, x):\n","       x = self.pool(self.relu(self.conv1(x)))\n","       x = self.pool(self.relu(self.conv2(x)))\n","       x = x.view(-1, self.conv2.out_channels * 7 * 7)\n","       x = self.relu(self.fc1(x))\n","       x = self.fc2(x)\n","       return x\n"],"metadata":{"id":"emzo6atw25YU","executionInfo":{"status":"ok","timestamp":1747700662840,"user_tz":420,"elapsed":3,"user":{"displayName":"Tejas Chopra","userId":"08409025920690368673"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Loading Dataset"],"metadata":{"id":"VeYWdlkr25rs"}},{"cell_type":"code","source":["# Load MNIST dataset\n","def load_data():\n","   transform = transforms.Compose([\n","       transforms.ToTensor(),\n","       transforms.Normalize((0.1307,), (0.3081,))\n","   ])\n","\n","\n","   trainset = torchvision.datasets.MNIST(root='./data', train=True,\n","                                        download=True, transform=transform)\n","   trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n","                                             shuffle=True, num_workers=2)\n","\n","\n","   testset = torchvision.datasets.MNIST(root='./data', train=False,\n","                                       download=True, transform=transform)\n","   testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n","                                            shuffle=False, num_workers=2)\n","   return trainloader, testloader\n","\n","\n"],"metadata":{"id":"oBfNi7KC27PC","executionInfo":{"status":"ok","timestamp":1747700665088,"user_tz":420,"elapsed":6,"user":{"displayName":"Tejas Chopra","userId":"08409025920690368673"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Utils for Evaluation"],"metadata":{"id":"C0vCsNPK27nI"}},{"cell_type":"code","source":["# Evaluate model accuracy\n","def evaluate_model(model, testloader):\n","   model.to(device)\n","   model.eval()\n","   correct = 0\n","   total = 0\n","   with torch.no_grad():\n","       for data in testloader:\n","           images, labels = data[0].to(device), data[1].to(device)\n","           outputs = model(images)\n","           _, predicted = torch.max(outputs.data, 1)\n","           total += labels.size(0)\n","           correct += (predicted == labels).sum().item()\n","\n","\n","   accuracy = 100 * correct / total\n","   return accuracy\n","\n","\n","# Measure inference time more accurately\n","def measure_inference_time(model, testloader, num_runs=3):\n","   model.to(device)\n","   model.eval()\n","\n","\n","   # Warm-up run\n","   with torch.no_grad():\n","       for data in testloader:\n","           images = data[0].to(device)\n","           _ = model(images)\n","\n","\n","   # Measure inference time\n","   torch.cuda.synchronize() if device.type == 'cuda' else None\n","   total_time = 0\n","\n","\n","   for _ in range(num_runs):\n","       start_time = time.time()\n","       with torch.no_grad():\n","           for data in testloader:\n","               images = data[0].to(device)\n","               _ = model(images)\n","       torch.cuda.synchronize() if device.type == 'cuda' else None\n","       end_time = time.time()\n","       total_time += (end_time - start_time)\n","\n","\n","   return total_time / num_runs\n","\n","\n","# Get model size in MB (more accurately)\n","def get_model_size(model, filename=\"temp_model.pth\"):\n","   # Save model in different formats to compare\n","   torch.save(model.state_dict(), filename)\n","   state_dict_size = os.path.getsize(filename) / (1024 * 1024)\n","\n","\n","   # Save as TorchScript for better compression of sparse models\n","   script_model = torch.jit.script(model.cpu())\n","   optimized_script_model = mobile_optimizer.optimize_for_mobile(script_model)\n","   script_filename = filename.replace('.pth', '.pt')\n","   optimized_script_model.save(script_filename)\n","   script_size = os.path.getsize(script_filename) / (1024 * 1024)\n","\n","\n","   # Clean up files\n","   if os.path.exists(filename):\n","       os.remove(filename)\n","   if os.path.exists(script_filename):\n","       os.remove(script_filename)\n","\n","\n","   return state_dict_size, script_size\n","\n","\n","# Count non-zero parameters\n","def count_parameters(model):\n","   total_params = 0\n","   nonzero_params = 0\n","   for param in model.parameters():\n","       total_params += param.numel()\n","       nonzero_params += torch.sum(param != 0).item()\n","   return total_params, nonzero_params\n"],"metadata":{"id":"idcs-b-t29ja","executionInfo":{"status":"ok","timestamp":1747700667152,"user_tz":420,"elapsed":8,"user":{"displayName":"Tejas Chopra","userId":"08409025920690368673"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Training"],"metadata":{"id":"CJ7E7I7r296K"}},{"cell_type":"code","source":["# Train the model\n","def train_model(model, trainloader, epochs=3):\n","   model.to(device)\n","   criterion = nn.CrossEntropyLoss()\n","   optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","\n","   for epoch in range(epochs):\n","       running_loss = 0.0\n","       for i, data in enumerate(trainloader, 0):\n","           inputs, labels = data[0].to(device), data[1].to(device)\n","           optimizer.zero_grad()\n","           outputs = model(inputs)\n","           loss = criterion(outputs, labels)\n","           loss.backward()\n","           optimizer.step()\n","           running_loss += loss.item()\n","\n","\n","           if i % 100 == 99:\n","               print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100:.3f}')\n","               running_loss = 0.0\n","\n","\n","   print('Finished Training')\n","   return model\n"],"metadata":{"id":"YOebCnA13D7Y","executionInfo":{"status":"ok","timestamp":1747700671290,"user_tz":420,"elapsed":4,"user":{"displayName":"Tejas Chopra","userId":"08409025920690368673"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Unstructured Pruning"],"metadata":{"id":"96e--RghH7Yt"}},{"cell_type":"code","source":["# Apply unstructured pruning with parameter removal\n","def apply_unstructured_pruning(model, prune_amount=0.5):\n","   print(\"Applying unstructured pruning...\")\n","   pruned_model = copy.deepcopy(model)\n","   pruned_model.cpu()  # Move to CPU for pruning operations\n","\n","\n","   # Apply pruning to all conv and linear layers\n","   for name, module in pruned_model.named_modules():\n","       if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n","           prune.l1_unstructured(module, name='weight', amount=prune_amount)\n","           # Make pruning permanent (removes the mask)\n","           prune.remove(module, 'weight')\n","\n","\n","   # For actual model size reduction in a real system, we would need\n","   # to convert this to a sparse format or create a new model with fewer parameters\n","   return pruned_model\n","\n","\n"],"metadata":{"id":"BNDF-05kH7zY","executionInfo":{"status":"ok","timestamp":1747700673268,"user_tz":420,"elapsed":5,"user":{"displayName":"Tejas Chopra","userId":"08409025920690368673"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["Structured Pruning"],"metadata":{"id":"00Z8u7ThH8KL"}},{"cell_type":"code","source":["# Implement actual structured pruning (removing channels)\n","def apply_structured_pruning(model, prune_amount=0.3):\n","   print(\"Applying structured pruning...\")\n","   original_model = model.cpu()  # Move to CPU for pruning operations\n","\n","\n","   # Get the original architecture parameters\n","   original_conv1_out = original_model.conv1.out_channels\n","   original_conv2_out = original_model.conv2.out_channels\n","   original_fc1_out = original_model.fc1.out_features\n","\n","\n","   # Calculate new dimensions after pruning\n","   new_conv1_out = int(original_conv1_out * (1 - prune_amount))\n","   new_conv2_out = int(original_conv2_out * (1 - prune_amount))\n","   new_fc1_out = int(original_fc1_out * (1 - prune_amount))\n","\n","\n","   # Create new model with reduced dimensions\n","   pruned_model = SimpleCNN(\n","       in_channels=1,\n","       conv1_channels=new_conv1_out,\n","       conv2_channels=new_conv2_out,\n","       fc1_units=new_fc1_out,\n","       fc2_units=10  # Output dimension remains the same\n","   )\n","\n","\n","   # For each layer, determine which channels to keep based on L2 norm\n","   # Conv1 layer\n","   conv1_weight = original_model.conv1.weight.data\n","   conv1_channel_norms = torch.norm(conv1_weight, p=2, dim=[1, 2, 3])\n","   _, conv1_indices = torch.topk(conv1_channel_norms, new_conv1_out)\n","   conv1_indices = sorted(conv1_indices.tolist())\n","\n","\n","   # Copy weights for kept channels in conv1\n","   pruned_model.conv1.weight.data = conv1_weight[conv1_indices]\n","   pruned_model.conv1.bias.data = original_model.conv1.bias.data[conv1_indices]\n","\n","\n","   # Conv2 layer (need to adjust input channels to match Conv1 output)\n","   conv2_weight = original_model.conv2.weight.data\n","   conv2_channel_norms = torch.norm(conv2_weight, p=2, dim=[1, 2, 3])\n","   _, conv2_indices = torch.topk(conv2_channel_norms, new_conv2_out)\n","   conv2_indices = sorted(conv2_indices.tolist())\n","\n","\n","   # Create a new weight tensor for conv2 with adjusted dimensions\n","   pruned_model.conv2.weight.data = torch.zeros(\n","       new_conv2_out, new_conv1_out,\n","       conv2_weight.size(2), conv2_weight.size(3)\n","   )\n","\n","\n","   # Copy weights for kept channels, adjusting for input channels\n","   for i, out_idx in enumerate(conv2_indices):\n","       for j, in_idx in enumerate(conv1_indices):\n","           pruned_model.conv2.weight.data[i, j] = conv2_weight[out_idx, in_idx]\n","\n","\n","   pruned_model.conv2.bias.data = original_model.conv2.bias.data[conv2_indices]\n","\n","\n","   # FC1 layer (need to adjust input to match Conv2 output)\n","   fc1_weight = original_model.fc1.weight.data\n","   fc1_output_norms = torch.norm(fc1_weight, p=2, dim=1)\n","   _, fc1_indices = torch.topk(fc1_output_norms, new_fc1_out)\n","   fc1_indices = sorted(fc1_indices.tolist())\n","\n","\n","   # Create a new weight tensor with adjusted dimensions\n","   pruned_model.fc1.weight.data = torch.zeros(\n","       new_fc1_out, new_conv2_out * 7 * 7\n","   )\n","\n","\n","   # This is a bit tricky - we need to reshape both matrices to account for\n","   # the changed conv2 output channels\n","   reshaped_old = fc1_weight.view(original_fc1_out, original_conv2_out, 7, 7)\n","   reshaped_new = pruned_model.fc1.weight.data.view(new_fc1_out, new_conv2_out, 7, 7)\n","\n","\n","   for i, out_idx in enumerate(fc1_indices):\n","       for j, in_idx in enumerate(conv2_indices):\n","           reshaped_new[i, j] = reshaped_old[out_idx, in_idx]\n","\n","\n","   pruned_model.fc1.bias.data = original_model.fc1.bias.data[fc1_indices]\n","\n","\n","   # FC2 layer\n","   fc2_weight = original_model.fc2.weight.data\n","   # Create a new weight tensor for FC2 with adjusted dimensions\n","   pruned_model.fc2.weight.data = torch.zeros(10, new_fc1_out)\n","\n","\n","   # Copy weights for kept FC1 output units\n","   for j, in_idx in enumerate(fc1_indices):\n","       pruned_model.fc2.weight.data[:, j] = fc2_weight[:, in_idx]\n","\n","\n","   pruned_model.fc2.bias.data = original_model.fc2.bias.data\n","\n","\n","   return pruned_model\n"],"metadata":{"id":"GptRGF93H8eR","executionInfo":{"status":"ok","timestamp":1747700674979,"user_tz":420,"elapsed":3,"user":{"displayName":"Tejas Chopra","userId":"08409025920690368673"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["Fine-Tuning"],"metadata":{"id":"3NJ9XSdZIBAx"}},{"cell_type":"code","source":["# Fine-tune the pruned model\n","def fine_tune_model(model, trainloader, epochs=2):\n","   model.to(device)\n","   criterion = nn.CrossEntropyLoss()\n","   optimizer = optim.Adam(model.parameters(), lr=0.0005)\n","\n","\n","   print(\"Fine-tuning the pruned model...\")\n","   for epoch in range(epochs):\n","       running_loss = 0.0\n","       for i, data in enumerate(trainloader, 0):\n","           inputs, labels = data[0].to(device), data[1].to(device)\n","           optimizer.zero_grad()\n","           outputs = model(inputs)\n","           loss = criterion(outputs, labels)\n","           loss.backward()\n","           optimizer.step()\n","           running_loss += loss.item()\n","\n","\n","           if i % 100 == 99:\n","               print(f'Fine-tuning Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100:.3f}')\n","               running_loss = 0.0\n","\n","\n","   print('Finished Fine-tuning')\n","   return model\n"],"metadata":{"id":"4bqe4nKMIBvi","executionInfo":{"status":"ok","timestamp":1747700678455,"user_tz":420,"elapsed":3,"user":{"displayName":"Tejas Chopra","userId":"08409025920690368673"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["Main Function"],"metadata":{"id":"9wGDOf_8HMfB"}},{"cell_type":"code","source":["# Main function to run the experiment\n","def main():\n","   import os\n","\n","\n","   # Load data\n","   trainloader, testloader = load_data()\n","\n","\n","   # Initialize and train the model\n","   print(\"Training original model...\")\n","   original_model = SimpleCNN()\n","   original_model = train_model(original_model, trainloader)\n","\n","\n","   # Evaluate original model\n","   print(\"\\nEvaluating original model...\")\n","   original_accuracy = evaluate_model(original_model, testloader)\n","   original_inference_time = measure_inference_time(original_model, testloader)\n","   original_state_dict_size, original_script_size = get_model_size(original_model)\n","   total_params, nonzero_params = count_parameters(original_model)\n","\n","\n","   print(\"\\n--- Original Model Metrics ---\")\n","   print(f\"Accuracy: {original_accuracy:.2f}%\")\n","   print(f\"Inference Time: {original_inference_time:.4f} seconds\")\n","   print(f\"Model Size (state_dict): {original_state_dict_size:.2f} MB\")\n","   print(f\"Model Size (TorchScript): {original_script_size:.2f} MB\")\n","   print(f\"Total Parameters: {total_params}\")\n","   print(f\"Non-zero Parameters: {nonzero_params} ({nonzero_params/total_params*100:.2f}%)\")\n","\n","\n","   # Clear memory\n","   gc.collect()\n","   torch.cuda.empty_cache() if device.type == 'cuda' else None\n","\n","\n","   # Apply unstructured pruning\n","   unstructured_model = apply_unstructured_pruning(original_model)\n","\n","\n","   # Evaluate unstructured pruned model\n","   print(\"\\nEvaluating unstructured pruned model...\")\n","   unstructured_accuracy = evaluate_model(unstructured_model, testloader)\n","   unstructured_inference_time = measure_inference_time(unstructured_model, testloader)\n","   unstructured_state_dict_size, unstructured_script_size = get_model_size(unstructured_model)\n","   total_params_u, nonzero_params_u = count_parameters(unstructured_model)\n","\n","\n","   print(\"\\n--- Unstructured Pruned Model Metrics ---\")\n","   print(f\"Accuracy: {unstructured_accuracy:.2f}%\")\n","   print(f\"Inference Time: {unstructured_inference_time:.4f} seconds\")\n","   print(f\"Model Size (state_dict): {unstructured_state_dict_size:.2f} MB\")\n","   print(f\"Model Size (TorchScript): {unstructured_script_size:.2f} MB\")\n","   print(f\"Total Parameters: {total_params_u}\")\n","   print(f\"Non-zero Parameters: {nonzero_params_u} ({nonzero_params_u/total_params_u*100:.2f}%)\")\n","   print(f\"Accuracy Drop: {original_accuracy - unstructured_accuracy:.2f}%\")\n","   print(f\"Inference Speedup: {original_inference_time / unstructured_inference_time:.2f}x\")\n","   print(f\"Size Reduction (state_dict): {(1 - unstructured_state_dict_size / original_state_dict_size) * 100:.2f}%\")\n","   print(f\"Size Reduction (TorchScript): {(1 - unstructured_script_size / original_script_size) * 100:.2f}%\")\n","\n","\n","   # Clear memory\n","   gc.collect()\n","   torch.cuda.empty_cache() if device.type == 'cuda' else None\n","\n","\n","   # Apply structured pruning\n","   structured_model = apply_structured_pruning(original_model)\n","\n","\n","   # Evaluate structured pruned model\n","   print(\"\\nEvaluating structured pruned model...\")\n","   structured_accuracy = evaluate_model(structured_model, testloader)\n","   structured_inference_time = measure_inference_time(structured_model, testloader)\n","   structured_state_dict_size, structured_script_size = get_model_size(structured_model)\n","   total_params_s, nonzero_params_s = count_parameters(structured_model)\n","\n","\n","   print(\"\\n--- Structured Pruned Model Metrics ---\")\n","   print(f\"Accuracy: {structured_accuracy:.2f}%\")\n","   print(f\"Inference Time: {structured_inference_time:.4f} seconds\")\n","   print(f\"Model Size (state_dict): {structured_state_dict_size:.2f} MB\")\n","   print(f\"Model Size (TorchScript): {structured_script_size:.2f} MB\")\n","   print(f\"Total Parameters: {total_params_s}\")\n","   print(f\"Non-zero Parameters: {nonzero_params_s} ({nonzero_params_s/total_params_s*100:.2f}%)\")\n","   print(f\"Accuracy Drop: {original_accuracy - structured_accuracy:.2f}%\")\n","   print(f\"Inference Speedup: {original_inference_time / structured_inference_time:.2f}x\")\n","   print(f\"Size Reduction (state_dict): {(1 - structured_state_dict_size / original_state_dict_size) * 100:.2f}%\")\n","   print(f\"Size Reduction (TorchScript): {(1 - structured_script_size / original_script_size) * 100:.2f}%\")\n","\n","\n","   # Fine-tune unstructured pruned model\n","   fine_tuned_unstructured = fine_tune_model(unstructured_model, trainloader)\n","\n","\n","   # Evaluate fine-tuned unstructured pruned model\n","   print(\"\\nEvaluating fine-tuned unstructured pruned model...\")\n","   fine_tuned_unstructured_accuracy = evaluate_model(fine_tuned_unstructured, testloader)\n","   fine_tuned_unstructured_inference = measure_inference_time(fine_tuned_unstructured, testloader)\n","\n","\n","   print(\"\\n--- Fine-tuned Unstructured Pruned Model Metrics ---\")\n","   print(f\"Accuracy: {fine_tuned_unstructured_accuracy:.2f}%\")\n","   print(f\"Inference Time: {fine_tuned_unstructured_inference:.4f} seconds\")\n","   print(f\"Accuracy Recovery: {fine_tuned_unstructured_accuracy - unstructured_accuracy:.2f}%\")\n","\n","\n","   # Fine-tune structured pruned model\n","   fine_tuned_structured = fine_tune_model(structured_model, trainloader)\n","\n","\n","   # Evaluate fine-tuned structured pruned model\n","   print(\"\\nEvaluating fine-tuned structured pruned model...\")\n","   fine_tuned_structured_accuracy = evaluate_model(fine_tuned_structured, testloader)\n","   fine_tuned_structured_inference = measure_inference_time(fine_tuned_structured, testloader)\n","\n","\n","   print(\"\\n--- Fine-tuned Structured Pruned Model Metrics ---\")\n","   print(f\"Accuracy: {fine_tuned_structured_accuracy:.2f}%\")\n","   print(f\"Inference Time: {fine_tuned_structured_inference:.4f} seconds\")\n","   print(f\"Accuracy Recovery: {fine_tuned_structured_accuracy - structured_accuracy:.2f}%\")\n","\n","\n","   # Summary comparison\n","   print(\"\\n--- Summary ---\")\n","   print(\"Model              | Accuracy | Inference Time | Size (MB) | Non-zero/Total Params\")\n","   print(\"--------------------|----------|----------------|-----------|--------------------\")\n","   print(f\"Original            | {original_accuracy:.2f}%   | {original_inference_time:.4f}s        | {original_script_size:.2f}    | {nonzero_params}/{total_params} ({nonzero_params/total_params*100:.1f}%)\")\n","   print(f\"Unstructured Pruned | {unstructured_accuracy:.2f}%   | {unstructured_inference_time:.4f}s        | {unstructured_script_size:.2f}    | {nonzero_params_u}/{total_params_u} ({nonzero_params_u/total_params_u*100:.1f}%)\")\n","   print(f\"+ Fine-tuned        | {fine_tuned_unstructured_accuracy:.2f}%   | {fine_tuned_unstructured_inference:.4f}s        | {unstructured_script_size:.2f}    | {nonzero_params_u}/{total_params_u} ({nonzero_params_u/total_params_u*100:.1f}%)\")\n","   print(f\"Structured Pruned   | {structured_accuracy:.2f}%   | {structured_inference_time:.4f}s        | {structured_script_size:.2f}    | {nonzero_params_s}/{total_params_s} ({nonzero_params_s/total_params_s*100:.1f}%)\")\n","   print(f\"+ Fine-tuned        | {fine_tuned_structured_accuracy:.2f}%   | {fine_tuned_structured_inference:.4f}s        | {structured_script_size:.2f}    | {nonzero_params_s}/{total_params_s} ({nonzero_params_s/total_params_s*100:.1f}%)\")\n","\n"],"metadata":{"id":"7-fxB6dMHQXQ","executionInfo":{"status":"ok","timestamp":1747700680497,"user_tz":420,"elapsed":6,"user":{"displayName":"Tejas Chopra","userId":"08409025920690368673"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vN5nVWEfgeye"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"DwaWGXubfvQB"}},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","   main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RL3t799Dfvqd","executionInfo":{"status":"ok","timestamp":1747700829913,"user_tz":420,"elapsed":145140,"user":{"displayName":"Tejas Chopra","userId":"08409025920690368673"}},"outputId":"bd42c585-9b1d-4348-b741-4612ccb7f1cd"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 18.2MB/s]\n","100%|██████████| 28.9k/28.9k [00:00<00:00, 481kB/s]\n","100%|██████████| 1.65M/1.65M [00:00<00:00, 4.47MB/s]\n","100%|██████████| 4.54k/4.54k [00:00<00:00, 6.81MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training original model...\n","Epoch 1, Batch 100, Loss: 0.570\n","Epoch 1, Batch 200, Loss: 0.162\n","Epoch 1, Batch 300, Loss: 0.098\n","Epoch 1, Batch 400, Loss: 0.087\n","Epoch 1, Batch 500, Loss: 0.088\n","Epoch 1, Batch 600, Loss: 0.064\n","Epoch 1, Batch 700, Loss: 0.065\n","Epoch 1, Batch 800, Loss: 0.065\n","Epoch 1, Batch 900, Loss: 0.048\n","Epoch 2, Batch 100, Loss: 0.049\n","Epoch 2, Batch 200, Loss: 0.041\n","Epoch 2, Batch 300, Loss: 0.053\n","Epoch 2, Batch 400, Loss: 0.036\n","Epoch 2, Batch 500, Loss: 0.045\n","Epoch 2, Batch 600, Loss: 0.040\n","Epoch 2, Batch 700, Loss: 0.033\n","Epoch 2, Batch 800, Loss: 0.038\n","Epoch 2, Batch 900, Loss: 0.036\n","Epoch 3, Batch 100, Loss: 0.030\n","Epoch 3, Batch 200, Loss: 0.034\n","Epoch 3, Batch 300, Loss: 0.031\n","Epoch 3, Batch 400, Loss: 0.030\n","Epoch 3, Batch 500, Loss: 0.023\n","Epoch 3, Batch 600, Loss: 0.034\n","Epoch 3, Batch 700, Loss: 0.021\n","Epoch 3, Batch 800, Loss: 0.027\n","Epoch 3, Batch 900, Loss: 0.026\n","Finished Training\n","\n","Evaluating original model...\n","\n","--- Original Model Metrics ---\n","Accuracy: 99.02%\n","Inference Time: 1.8192 seconds\n","Model Size (state_dict): 1.61 MB\n","Model Size (TorchScript): 1.61 MB\n","Total Parameters: 421642\n","Non-zero Parameters: 421642 (100.00%)\n","Applying unstructured pruning...\n","\n","Evaluating unstructured pruned model...\n","\n","--- Unstructured Pruned Model Metrics ---\n","Accuracy: 97.53%\n","Inference Time: 2.0523 seconds\n","Model Size (state_dict): 1.61 MB\n","Model Size (TorchScript): 1.61 MB\n","Total Parameters: 421642\n","Non-zero Parameters: 210938 (50.03%)\n","Accuracy Drop: 1.49%\n","Inference Speedup: 0.89x\n","Size Reduction (state_dict): 0.00%\n","Size Reduction (TorchScript): 0.00%\n","Applying structured pruning...\n","\n","Evaluating structured pruned model...\n","\n","--- Structured Pruned Model Metrics ---\n","Accuracy: 98.69%\n","Inference Time: 2.0910 seconds\n","Model Size (state_dict): 0.77 MB\n","Model Size (TorchScript): 0.78 MB\n","Total Parameters: 201849\n","Non-zero Parameters: 201849 (100.00%)\n","Accuracy Drop: 0.33%\n","Inference Speedup: 0.87x\n","Size Reduction (state_dict): 52.04%\n","Size Reduction (TorchScript): 51.97%\n","Fine-tuning the pruned model...\n","Fine-tuning Epoch 1, Batch 100, Loss: 0.019\n","Fine-tuning Epoch 1, Batch 200, Loss: 0.016\n","Fine-tuning Epoch 1, Batch 300, Loss: 0.017\n","Fine-tuning Epoch 1, Batch 400, Loss: 0.018\n","Fine-tuning Epoch 1, Batch 500, Loss: 0.015\n","Fine-tuning Epoch 1, Batch 600, Loss: 0.015\n","Fine-tuning Epoch 1, Batch 700, Loss: 0.017\n","Fine-tuning Epoch 1, Batch 800, Loss: 0.017\n","Fine-tuning Epoch 1, Batch 900, Loss: 0.015\n","Fine-tuning Epoch 2, Batch 100, Loss: 0.010\n","Fine-tuning Epoch 2, Batch 200, Loss: 0.008\n","Fine-tuning Epoch 2, Batch 300, Loss: 0.007\n","Fine-tuning Epoch 2, Batch 400, Loss: 0.010\n","Fine-tuning Epoch 2, Batch 500, Loss: 0.009\n","Fine-tuning Epoch 2, Batch 600, Loss: 0.012\n","Fine-tuning Epoch 2, Batch 700, Loss: 0.012\n","Fine-tuning Epoch 2, Batch 800, Loss: 0.012\n","Fine-tuning Epoch 2, Batch 900, Loss: 0.015\n","Finished Fine-tuning\n","\n","Evaluating fine-tuned unstructured pruned model...\n","\n","--- Fine-tuned Unstructured Pruned Model Metrics ---\n","Accuracy: 99.11%\n","Inference Time: 1.8783 seconds\n","Accuracy Recovery: 1.58%\n","Fine-tuning the pruned model...\n","Fine-tuning Epoch 1, Batch 100, Loss: 0.015\n","Fine-tuning Epoch 1, Batch 200, Loss: 0.018\n","Fine-tuning Epoch 1, Batch 300, Loss: 0.019\n","Fine-tuning Epoch 1, Batch 400, Loss: 0.023\n","Fine-tuning Epoch 1, Batch 500, Loss: 0.012\n","Fine-tuning Epoch 1, Batch 600, Loss: 0.016\n","Fine-tuning Epoch 1, Batch 700, Loss: 0.016\n","Fine-tuning Epoch 1, Batch 800, Loss: 0.014\n","Fine-tuning Epoch 1, Batch 900, Loss: 0.014\n","Fine-tuning Epoch 2, Batch 100, Loss: 0.009\n","Fine-tuning Epoch 2, Batch 200, Loss: 0.008\n","Fine-tuning Epoch 2, Batch 300, Loss: 0.012\n","Fine-tuning Epoch 2, Batch 400, Loss: 0.012\n","Fine-tuning Epoch 2, Batch 500, Loss: 0.010\n","Fine-tuning Epoch 2, Batch 600, Loss: 0.008\n","Fine-tuning Epoch 2, Batch 700, Loss: 0.008\n","Fine-tuning Epoch 2, Batch 800, Loss: 0.010\n","Fine-tuning Epoch 2, Batch 900, Loss: 0.014\n","Finished Fine-tuning\n","\n","Evaluating fine-tuned structured pruned model...\n","\n","--- Fine-tuned Structured Pruned Model Metrics ---\n","Accuracy: 99.11%\n","Inference Time: 1.8563 seconds\n","Accuracy Recovery: 0.42%\n","\n","--- Summary ---\n","Model              | Accuracy | Inference Time | Size (MB) | Non-zero/Total Params\n","--------------------|----------|----------------|-----------|--------------------\n","Original            | 99.02%   | 1.8192s        | 1.61    | 421642/421642 (100.0%)\n","Unstructured Pruned | 97.53%   | 2.0523s        | 1.61    | 210938/421642 (50.0%)\n","+ Fine-tuned        | 99.11%   | 1.8783s        | 1.61    | 210938/421642 (50.0%)\n","Structured Pruned   | 98.69%   | 2.0910s        | 0.78    | 201849/201849 (100.0%)\n","+ Fine-tuned        | 99.11%   | 1.8563s        | 0.78    | 201849/201849 (100.0%)\n"]}]}]}